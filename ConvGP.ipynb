{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from  scipy import ndimage, ndarray\n",
    "import skimage.measure\n",
    "from sklearn import metrics\n",
    "from deap import algorithms, base, creator, tools, gp\n",
    "import random, operator, math\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import pygraphviz as pgv\n",
    "from autograd import grad\n",
    "import datetime\n",
    "from inspect import isclass\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parameter settings\n",
    "Various custom parameter settings for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Which data to use\n",
    "data_directory = \"data/\"\n",
    "dataset_name = \"jaffe\"\n",
    "training_split = 0.8 # 80% of the data for training\n",
    "\n",
    "# For Convolutions\n",
    "pooling_size = 2 # Use 2x2 pooling\n",
    "filter_size = 3 # Use 3x3 filters\n",
    "\n",
    "# For GP\n",
    "tourn_size = 7\n",
    "num_best = 3\n",
    "pop_size = 1024\n",
    "crs_rate = 0.75\n",
    "mut_rate = 0.2\n",
    "# Reproduction rate is automatically set to 1-crs_rate-mut_rate\n",
    "generations = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data for training/testing\n",
    "1. Read the images from disk\n",
    "2. Save these in a dict from label -> images\n",
    "3. Split these based off label into training/testing images\n",
    "\n",
    "Need to do it in this order to ensure we get an equal split of instances from each class in the data, since classification accuracy is used as fitness this is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads in all the data as a dict from label -> [images]\n",
    "def read_data(directory):\n",
    "    data = {}\n",
    "\n",
    "    # Assumes the images are in subfolders, where the folder name is the images label\n",
    "    for subdir in glob(directory+\"/*/\"):\n",
    "        label = subdir.split(\"/\")[-2] # Second to last element is thee class/sub folder name\n",
    "        images = [ndimage.imread(image) for image in glob(subdir+\"/*.*\")] # Read in all the images from subdirectories\n",
    "        # Shuffle the images (seed specified at the top of program so this will be reproducable)\n",
    "        random.shuffle(images)\n",
    "        data[label] = images\n",
    "        \n",
    "    # Set of all class labels\n",
    "    labels = list(data.keys())\n",
    "\n",
    "    # Sanity check\n",
    "    if len(labels) != 2:\n",
    "        print(\"Binary classification only! But labels found were:\", labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Splits the data into two arrays (training and testing) of (label, image) pairs\n",
    "def format_and_split_data(data, labels, split):\n",
    "    training = []\n",
    "    testing = []\n",
    "    \n",
    "    # For all the classes, split into training/testing (need to do it per class to ensure we get a good split of all classes)\n",
    "    for label in labels:\n",
    "        pairs = [(label, image) for image in data[label]]\n",
    "        length = int(len(pairs) * split)\n",
    "        training.extend(pairs[:length])\n",
    "        testing.extend(pairs[length:])\n",
    "        \n",
    "    random.shuffle(training)\n",
    "    random.shuffle(testing)\n",
    "    \n",
    "    return training, testing\n",
    "        \n",
    "# Read and split data into training and testing    \n",
    "data, labels = read_data(data_directory+dataset_name)\n",
    "training_data, testing_data = format_and_split_data(data, labels, training_split)\n",
    "\n",
    "# We now have two lists of (label, image) pairs, one for training and one for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup GP\n",
    "\n",
    "Below the function and terminal set are defined. Strongly typed\n",
    "GP is used to enforce a tiered structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a custom class to represent an image, really just a wrapper around ndarray for more explicit typing\n",
    "class Image:\n",
    "    def __init__(self, pixels):\n",
    "        self.pixels = pixels\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Image(\"+repr(self.pixels)+\")\"\n",
    "    \n",
    "    __repr__ = __str__\n",
    "        \n",
    "# Program Takes in a single image as input. Outputs a float which is then used for classification by thresholding\n",
    "pset = gp.PrimitiveSetTyped(\"MAIN\", [Image], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# Terminal set\n",
    "# Three tiers - Convolution, Aggregation and Classification\n",
    "# ================\n",
    "\n",
    "# Image is a terminal for Convolution and aggregation tier, but this is defined above (when defining pset)\n",
    "\n",
    "# Add a random float between -1 and 1 (can be used in classification tier)\n",
    "pset.addEphemeralConstant(\"Random\", lambda: random.uniform(-1, 1), float)\n",
    "\n",
    "# ------------------\n",
    "# Convolution Tier\n",
    "# ------------------\n",
    "# Only specific terminal here is the filter/kernel to apply. \n",
    "\n",
    "# Kernel/filters, begin with a list of random values. This will be treated as a filter_size x filter_size array when applying\n",
    "pset.addEphemeralConstant(\"Kernel\", lambda: [random.randint(-3, 3) for _ in range(filter_size * filter_size)] , list)\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Aggregation Tier\n",
    "# ------------------\n",
    "# Four possible aggregation window shapes\n",
    "shapes = [\"Ellipse\", \"Rectangle\", \"Row\", \"Column\"]\n",
    "pset.addEphemeralConstant(\"Shape\", lambda: random.choice(shapes), str)\n",
    "\n",
    "\n",
    "# For x, y, width and height of window. Used as a percentage of width/height of image \n",
    "pset.addEphemeralConstant(\"Pos\", lambda: random.randint(5, 90), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for performing aggregation over regions of the image for the aggregation functions (i.e. the aggregation tier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the pixel values from an ellipse shape cut in the image\n",
    "def extract_ellipse(pixels, center_x, center_y, agg_width, agg_height):   \n",
    "    # Create an empty (black = 0) nparray same shape as the image, then make a ellipse cut in this array (=1)\n",
    "    mask = np.zeros_like(pixels)\n",
    "    mask = cv2.ellipse(mask, center=(center_x, center_y), axes=(agg_width, agg_height), angle=0, startAngle=0, endAngle=360, color=(1), thickness=-1)\n",
    "\n",
    "    # Apply the cutout to original image, only caring about the non zero parts of mask (as these are the pixels in the ellipse)\n",
    "    return pixels[mask > 0]\n",
    "\n",
    "def extract_window(image, shape, x, y, w, h):\n",
    "    pixels = image.pixels\n",
    "    dimensions = pixels.shape\n",
    "    \n",
    "    # Image is in row, col order\n",
    "    img_width = dimensions[1]\n",
    "    img_height = dimensions[0]\n",
    "    \n",
    "    # Convert to integers so we can use for indexing\n",
    "    x_start = int(x * img_width)\n",
    "    y_start = int(y * img_height)\n",
    "    agg_width = int(w  * img_width)\n",
    "    agg_height = int(h * img_height)\n",
    "    \n",
    "    # Ensure we are within the images bounds\n",
    "    x_end = min(x_start + agg_width, img_width)\n",
    "    y_end = min(y_start + agg_height, img_height)\n",
    "    \n",
    "    values = None\n",
    "    \n",
    "    # Need to extract different regions based off the shape\n",
    "    if shape == \"Rectangle\":\n",
    "        values = pixels[y_start:y_end, x_start:x_end]\n",
    "    elif shape == \"Column\":\n",
    "        values = pixels[y_start:y_end, x_start:min(x_start+1, img_width)]\n",
    "    elif shape == \"Row\":\n",
    "        values = pixels[y_start:min(y_start+1, img_height), x_start:x_end]\n",
    "    elif shape == \"Ellipse\":\n",
    "        values = extract_ellipse(pixels, x_start, y_start, agg_width, agg_height)\n",
    "    else:\n",
    "        print(\"Shape not found!!\")\n",
    "    \n",
    "    # Convert to a 1d array\n",
    "    if values is not None:\n",
    "        values.flatten()\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================\n",
    "# Function set\n",
    "# Three tiers - Convolution, Aggregation and Classification\n",
    "# ================\n",
    "\n",
    "# ------------------\n",
    "# Convolution Tier\n",
    "# ------------------\n",
    "\n",
    "# Convolve takes an image and a filter to apply, and returns the convolved image. Uses zero padding for the convolution\n",
    "def convolve(image, kernel_values):\n",
    "    # Currently kernel is a list but we want a 2d array\n",
    "    kernel = np.asarray(kernel_values).reshape((filter_size, filter_size))\n",
    "    # Use the constant mode, and padding value of zero to deal with edges of image\n",
    "    return Image(ndimage.filters.convolve(image.pixels, kernel, mode='constant', cval=0.0))\n",
    "    \n",
    "pset.addPrimitive(convolve, [Image, list], Image, name=\"Convolution\")\n",
    "\n",
    "# Pooling takes an image, and returns a subsampled version. Uses max pooling of the specified size\n",
    "def pooling(image):\n",
    "    return Image(skimage.measure.block_reduce(image.pixels, (pooling_size, pooling_size), np.max))\n",
    "    \n",
    "pset.addPrimitive(pooling, [Image], Image, name=\"Pooling\")\n",
    "\n",
    "# ------------------\n",
    "# Aggregation Tier\n",
    "# ------------------\n",
    "\n",
    "# Take a shape/region of the image and apply the given function to this region\n",
    "def agg(fn, image, shape, x, y, width, height):\n",
    "    # They are integers, treat them as floats instead when passing through\n",
    "    window = extract_window(image, shape, x/100.0, y/100.0, width/100.0, height/100.0)\n",
    "    return fn(window) if window.size > 0 else 0\n",
    "\n",
    "# Pass all the arguments and appropriate statistical operator on to the agg function above\n",
    "# The inputs correspond to: Image, Shape, X, Y, Width, Height\n",
    "pset.addPrimitive(lambda *args: agg(np.min, *args), [Image, str, int, int, int, int], float, name=\"aggmin\")\n",
    "pset.addPrimitive(lambda *args: agg(np.mean, *args), [Image, str, int, int, int, int], float, name=\"aggmean\")\n",
    "pset.addPrimitive(lambda *args: agg(np.max, *args), [Image, str, int, int, int, int], float, name=\"aggmax\")\n",
    "pset.addPrimitive(lambda *args: agg(np.std, *args), [Image, str, int, int, int, int], float, name=\"aggstd\")\n",
    "\n",
    "# ------------------\n",
    "# Classification Tier\n",
    "# ------------------\n",
    "def protectedDiv(num, den):\n",
    "    try:\n",
    "        return num / den\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "# Use the basic arithmetic operators\n",
    "pset.addPrimitive(operator.add, [float, float], float)\n",
    "pset.addPrimitive(operator.sub, [float, float], float)\n",
    "pset.addPrimitive(operator.mul, [float, float], float)\n",
    "pset.addPrimitive(protectedDiv, [float, float], float, name=\"div\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function\n",
    "Use classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How should fitness of an individual be determined? In this case use classification accuracy\n",
    "def fitness_function(individual, data, label_set):            \n",
    "    # Transform the tree expression in a callable function\n",
    "    output = toolbox.compile(expr=individual)\n",
    "    \n",
    "    # Any arbitrary threshold can be used, zero is nice as it means negatives = class1, non negatives = class2\n",
    "    threshold = 0\n",
    "    \n",
    "    real_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for (real_label, image) in data:\n",
    "        real_labels.append(real_label)\n",
    "            \n",
    "        out = output(Image(image))\n",
    "        if out > threshold:\n",
    "            predicted_labels.append(label_set[0])\n",
    "        else:\n",
    "            predicted_labels.append(label_set[1])\n",
    "    \n",
    "    real_labels = np.asarray(real_labels)\n",
    "    predicted_labels = np.asarray(predicted_labels)\n",
    "\n",
    "    # Count of elementwise matches\n",
    "    classification_accuracy = metrics.accuracy_score(real_labels, predicted_labels)\n",
    "\n",
    "    # Deap requires multiple values be returned, so the comma is important!\n",
    "    return classification_accuracy, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEAP has some issues with strongly typed GP and tree generation (see here: https://groups.google.com/forum/#!searchin/deap-users/stgp/deap-users/YOeb65eRNG4/AYUMcNldhdwJ and here: https://groups.google.com/forum/#!msg/deap-users/adq50--lzJ4/hefHPJKpBQAJ )\n",
    "# The following code replaces some of the code in DEAP, to make this work. \n",
    "\n",
    "# The block off code below be ignored, essentially its a workaround to stop the need for \"identity nodes\" which bloat the trees, to fix\n",
    "# the issue of strongly typed trees not being able to be generated in particular circumstances (i.e. full method but cant happen with current types)\n",
    "\n",
    "# genHalfAndHalf, genFull and genGrow copied directly from deap (https://github.com/DEAP/deap/blob/master/deap/gp.py)\n",
    "def genFull(pset, min_, max_, type_=None):\n",
    "    def condition(height, depth):\n",
    "        \"\"\"Expression generation stops when the depth is equal to height.\"\"\"\n",
    "        return depth == height\n",
    "    return generate(pset, min_, max_, condition, type_)\n",
    "\n",
    "def genGrow(pset, min_, max_, type_=None):\n",
    "    def condition(height, depth):\n",
    "        \"\"\"Expression generation stops when the depth is equal to height\n",
    "        or when it is randomly determined that a a node should be a terminal.\n",
    "        \"\"\"\n",
    "        return depth == height or \\\n",
    "            (depth >= min_ and random.random() < pset.terminalRatio)\n",
    "    return generate(pset, min_, max_, condition, type_)\n",
    "\n",
    "\n",
    "def genHalfAndHalf(pset, min_, max_, type_=None):\n",
    "    method = random.choice((genGrow, genFull))\n",
    "    return method(pset, min_, max_, type_)\n",
    "\n",
    "# Small change made to method below from DEAP version. If you try and add a primtiive, but none of the appropriate type\n",
    "# is available, then try add a terminal instead.\n",
    "def generate(pset, min_, max_, condition, type_=None):\n",
    "    \"\"\"Generate a Tree as a list of list. The tree is build\n",
    "    from the root to the leaves, and it stop growing when the\n",
    "    condition is fulfilled.\n",
    "    :param pset: Primitive set from which primitives are selected.\n",
    "    :param min_: Minimum height of the produced trees.\n",
    "    :param max_: Maximum Height of the produced trees.\n",
    "    :param condition: The condition is a function that takes two arguments,\n",
    "                      the height of the tree to build and the current\n",
    "                      depth in the tree.\n",
    "    :param type_: The type that should return the tree when called, when\n",
    "                  :obj:`None` (default) the type of :pset: (pset.ret)\n",
    "                  is assumed.\n",
    "    :returns: A grown tree with leaves at possibly different depths\n",
    "              dependending on the condition function.\n",
    "    \"\"\"\n",
    "    if type_ is None:\n",
    "        type_ = pset.ret\n",
    "    expr = []\n",
    "    height = random.randint(min_, max_)\n",
    "    stack = [(0, type_)]\n",
    "    while len(stack) != 0:\n",
    "        depth, type_ = stack.pop()\n",
    "        \n",
    "        # If we are at the end of a branch, add a terminal\n",
    "        if condition(height, depth):\n",
    "            term = add_terminal(pset, type_)\n",
    "            expr.append(term)\n",
    "            \n",
    "        # Otherwise add a terminal    \n",
    "        else:\n",
    "            try:\n",
    "                prim = random.choice(pset.primitives[type_])\n",
    "                expr.append(prim)\n",
    "                for arg in reversed(prim.args):\n",
    "                    stack.append((depth + 1, arg))\n",
    "            except IndexError: \n",
    "                # This is where the change occurs, if no primitive is available, try and add a terminal instead\n",
    "                term = add_terminal(pset, type_)\n",
    "                expr.append(term)\n",
    "            \n",
    "    return expr\n",
    "\n",
    "def add_terminal(pset, type_):\n",
    "    try:\n",
    "        term = random.choice(pset.terminals[type_])\n",
    "    except IndexError:\n",
    "        _, _, traceback = sys.exc_info()\n",
    "        raise IndexError(\"The custom generate function tried to add \"\\\n",
    "                          \"a terminal of type '%s', but there is \"\\\n",
    "                          \"none available.\" % (type_,), traceback)\n",
    "    if isclass(term):\n",
    "        term = term()\n",
    "    \n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This a maximization problem, as fitness is classification accuracy (higher the better)\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "\n",
    "# Individuals in the population should be represented as tree structures (standard GP)\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Ramped Half and half generation (full and grow\n",
    "toolbox.register(\"expr\", genHalfAndHalf, pset=pset, min_=2, max_=5)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "\n",
    "# Tournament size\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=tourn_size)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "# Max tree heights for crossover and mutation\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=10))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=10))\n",
    "\n",
    "# Need to say how evaluation should be performed, in this case its passing the training data to the defined fitness function\n",
    "toolbox.register(\"evaluate\", fitness_function, data=training_data, label_set=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data to track per generation. Track the min, mean, std, max of the fitness and tree sizes \n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats_size = tools.Statistics(len)\n",
    "\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  To Plot/draw the resulting trees\n",
    "def plot(tree):\n",
    "    nodes, edges, labels = gp.graph(tree)\n",
    "\n",
    "    g = pgv.AGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    g.layout(prog=\"dot\")\n",
    "\n",
    "    for i in nodes:\n",
    "        n = g.get_node(i)\n",
    "        n.attr[\"label\"] = labels[i]\n",
    "\n",
    "    g.draw(\"trees/\"+dataset_name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "<string>:1: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in ubyte_scalars\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in ubyte_scalars\n",
      "<string>:1: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                 fitness                 \t              size             \n",
      "   \t      \t-----------------------------------------\t-------------------------------\n",
      "gen\tnevals\tavg     \tmax   \tmin \tstd      \tavg    \tmax\tmin\tstd    \n",
      "0  \t1024  \t0.500854\t0.6875\t0.25\t0.0183944\t16.5547\t86 \t7  \t11.2454\n",
      "1  \t818   \t0.509135\t0.729167\t0.3125\t0.0320411\t17.5664\t87 \t1  \t11.9591\n",
      "2  \t828   \t0.534709\t0.729167\t0.3125\t0.0512373\t20.1855\t94 \t1  \t14.231 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  \t821   \t0.580526\t0.791667\t0.3125\t0.074576 \t20.7871\t69 \t1  \t14.4078\n",
      "4  \t835   \t0.633931\t0.8125  \t0.270833\t0.0841099\t27.3418\t66 \t1  \t11.8299\n",
      "5  \t841   \t0.641907\t0.833333\t0.208333\t0.0977791\t28.334 \t61 \t1  \t10.3763\n",
      "6  \t823   \t0.662292\t0.895833\t0.3125  \t0.114553 \t24.1348\t61 \t1  \t9.82003\n",
      "7  \t813   \t0.685201\t0.895833\t0.333333\t0.130307 \t20.6758\t45 \t1  \t8.30888\n",
      "8  \t812   \t0.706034\t0.9375  \t0.291667\t0.141808 \t21.6973\t53 \t1  \t8.59018\n",
      "9  \t826   \t0.736328\t0.958333\t0.3125  \t0.155996 \t19.9209\t45 \t1  \t6.7841 \n",
      "10 \t845   \t0.773885\t0.958333\t0.125   \t0.161647 \t17.3555\t41 \t1  \t2.85568\n",
      "11 \t809   \t0.795797\t0.979167\t0.208333\t0.165332 \t16.9277\t35 \t1  \t2.04745\n",
      "12 \t801   \t0.812622\t1       \t0.166667\t0.166997 \t16.9326\t26 \t7  \t1.74339\n",
      "13 \t826   \t0.81547 \t1       \t0.166667\t0.178111 \t16.7734\t24 \t1  \t2.19851\n",
      "14 \t788   \t0.849955\t1       \t0.25    \t0.180808 \t16.7061\t26 \t1  \t2.12374\n",
      "15 \t836   \t0.864766\t1       \t0.3125  \t0.194741 \t15.7959\t22 \t1  \t2.10523\n",
      "16 \t798   \t0.882629\t1       \t0.291667\t0.196586 \t15.0371\t23 \t1  \t1.78333\n",
      "17 \t810   \t0.883952\t1       \t0.25    \t0.195634 \t14.9678\t24 \t1  \t1.33021\n",
      "18 \t794   \t0.894552\t1       \t0.208333\t0.192357 \t15.0254\t23 \t1  \t1.14792\n",
      "19 \t790   \t0.903076\t1       \t0.291667\t0.187866 \t14.9541\t23 \t1  \t1.28576\n",
      "20 \t825   \t0.875509\t1       \t0.291667\t0.203165 \t14.8887\t23 \t1  \t1.66164\n",
      "21 \t826   \t0.885885\t1       \t0.25    \t0.196976 \t14.9717\t23 \t1  \t1.54559\n",
      "22 \t814   \t0.874919\t1       \t0.291667\t0.20541  \t14.8984\t20 \t1  \t1.49851\n",
      "23 \t814   \t0.868998\t1       \t0.229167\t0.203833 \t14.9795\t23 \t1  \t1.40332\n",
      "24 \t794   \t0.893758\t1       \t0.166667\t0.192673 \t15.0059\t23 \t1  \t1.0634 \n",
      "25 \t818   \t0.888387\t1       \t0.291667\t0.194601 \t14.9854\t23 \t1  \t1.36028\n",
      "26 \t807   \t0.881022\t1       \t0.208333\t0.1993   \t15.0391\t23 \t1  \t1.29166\n",
      "27 \t814   \t0.895121\t1       \t0.291667\t0.190709 \t14.9639\t23 \t1  \t1.55801\n",
      "28 \t846   \t0.873067\t1       \t0.291667\t0.203894 \t15.0156\t23 \t1  \t1.26311\n",
      "29 \t826   \t0.889771\t1       \t0.333333\t0.194609 \t14.9619\t23 \t1  \t1.39457\n",
      "30 \t819   \t0.876099\t1       \t0.333333\t0.201637 \t14.9014\t23 \t1  \t1.57093\n",
      "31 \t839   \t0.880229\t1       \t0.333333\t0.203098 \t14.8506\t23 \t1  \t1.71338\n",
      "32 \t791   \t0.870544\t1       \t0.270833\t0.209239 \t14.9482\t23 \t1  \t1.40251\n",
      "33 \t845   \t0.875488\t1       \t0.291667\t0.206977 \t14.9443\t20 \t1  \t1.23262\n",
      "34 \t824   \t0.870178\t1       \t0.333333\t0.20811  \t14.8916\t23 \t1  \t1.61625\n",
      "35 \t804   \t0.895854\t1       \t0.3125  \t0.190007 \t14.9863\t19 \t1  \t1.1327 \n",
      "36 \t789   \t0.884847\t1       \t0.3125  \t0.200581 \t14.9375\t23 \t1  \t1.43818\n",
      "37 \t825   \t0.87734 \t1       \t0.1875  \t0.203029 \t14.8506\t19 \t1  \t1.59287\n",
      "38 \t834   \t0.876933\t1       \t0.270833\t0.204064 \t14.9053\t23 \t1  \t1.59645\n",
      "39 \t843   \t0.875122\t1       \t0.3125  \t0.204717 \t14.9316\t20 \t1  \t1.514  \n",
      "40 \t824   \t0.877523\t1       \t0.166667\t0.206146 \t14.8975\t19 \t1  \t1.46183\n",
      "41 \t823   \t0.885498\t1       \t0.3125  \t0.196884 \t14.8799\t23 \t1  \t1.66073\n",
      "42 \t801   \t0.883179\t1       \t0.333333\t0.199149 \t14.9678\t24 \t1  \t1.42177\n",
      "43 \t826   \t0.887797\t1       \t0.333333\t0.193565 \t14.9961\t23 \t1  \t1.33097\n",
      "44 \t832   \t0.866313\t1       \t0.229167\t0.206255 \t14.8965\t23 \t1  \t1.79709\n",
      "45 \t848   \t0.894124\t1       \t0.291667\t0.187409 \t14.9277\t23 \t1  \t1.508  \n",
      "46 \t804   \t0.881978\t1       \t0.270833\t0.201609 \t15.0059\t24 \t1  \t1.46641\n",
      "47 \t792   \t0.882263\t1       \t0.270833\t0.199585 \t15.0615\t23 \t1  \t1.29117\n",
      "48 \t784   \t0.880859\t1       \t0.3125  \t0.200735 \t15.0059\t23 \t1  \t1.44224\n",
      "49 \t827   \t0.881368\t1       \t0.208333\t0.200431 \t15.0098\t23 \t1  \t1.47833\n",
      "50 \t785   \t0.88737 \t1       \t0.291667\t0.197813 \t15.0049\t19 \t1  \t1.30316\n"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(n=pop_size)\n",
    "hof = tools.HallOfFame(num_best)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, crs_rate, mut_rate, generations, stats=mstats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the evolved solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the fittest individual, and plot to a file\n",
    "best = hof[0]\n",
    "plot(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916666666667\n"
     ]
    }
   ],
   "source": [
    "testing_accuracy = fitness_function(best, testing_data, labels)[0]\n",
    "print(testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
